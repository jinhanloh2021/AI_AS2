\item In this question, you will employ Singular Value Decomposition to obtain word embeddings and compare the generated word embeddings with the word embeddings generated using word2vec. The corpus to be considered is a set of tweets posted about the Covid- 19 pandemic on Twitter (\lstinline{Corona_Tweets.csv}), which is a real-life dataset. You need to do the following (code template provided is \lstinline{Q4_template_tweets.ipynb} you are free to use helper functions if required):
\begin{enumerate}
  \item Update the \lstinline{load_data} function from the \lstinline{Q4_template_tweets.ipynb} to preprocess words: remove non-letters, convert words into the lower case, and remove the stop words. You can employ some functions from the \lstinline{NLP-pipeline-example.ipynb} example and may use regular expressions from \lstinline{Word2Vec.ipynb}. {\bf [2 marks]}
  \item Create the co-occurrence matrix for all the remaining words (after stop words are eliminated), where the window of co-occurrence is 5 on either side of the word. What is the size of your vocabulary (i.e., how many unique words you end up with)? \textbf{[4 marks]}
  \item Apply SVD and obtain word embeddings of size 75. {\bf [2 marks]}
  \item Then, please generate word embeddings of size 75 using \lstinline{Word2Vec.ipynb} (uploaded in class lecture material) on the same dataset. Please show comparison on few examples to understand which method works better. You may use the \lstinline{svd.most_similar} function from the template to perform the comparisons. Note your observations in your solution. You can use words like “covid”, “grocery” etc to compare the two models. {\bf [2 marks]}
\end{enumerate}